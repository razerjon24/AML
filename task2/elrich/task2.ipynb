{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 1000)\n",
      "(4800, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_raw = pd.read_csv('../data/X_train.csv').drop('id', axis=1)\n",
    "y_train_raw = pd.read_csv('../data/y_train.csv').drop('id', axis=1)\n",
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3600\n",
       "2     600\n",
       "0     600\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_counts = y_train_raw.y.value_counts()\n",
    "y_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get balanced accuracy score\n",
    "def score(true, pred):\n",
    "    return balanced_accuracy_score(true, pred)\n",
    "\n",
    "# Oversample using SMOTE\n",
    "def oversample(x_data, y_data):\n",
    "    smote = SMOTE(ratio='not majority')\n",
    "    return smote.fit_sample(x_data, y_data)\n",
    "\n",
    "# Oversample and fit model for a CV split\n",
    "def run_fold(x_train, y_train, x_test, y_test, model):\n",
    "    # Oversample data\n",
    "    x_train_sm, y_train_sm = oversample(x_train, y_train)\n",
    "    # Fit model\n",
    "    model.fit(x_train_sm, y_train_sm)\n",
    "    y_train_pred = model.predict(x_train_sm)\n",
    "    train_score = score(y_train_sm, y_train_pred)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    test_score = score(y_test, y_test_pred)\n",
    "    return test_score, train_score\n",
    "\n",
    "def cross_validate(x_data, y_data, model):\n",
    "    # Split data into folds\n",
    "    n_splits = 10\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    folds = kf.split(x_data)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    times = []\n",
    "    split = 0\n",
    "    for train_index, test_index in folds:\n",
    "        split += 1\n",
    "        print('Running split {}/{}'.format(split, n_splits))\n",
    "        x_train = x_data[train_index]\n",
    "        y_train = y_data[train_index]\n",
    "        x_test = x_data[test_index]\n",
    "        y_test = y_data[test_index]\n",
    "        start_time = time.time()\n",
    "        test_score, train_score = run_fold(x_train, y_train, x_test, y_test, model)\n",
    "        end_time = time.time()\n",
    "        total_time = round(end_time-start_time, ndigits=0)\n",
    "        test_scores.append(test_score)\n",
    "        train_scores.append(train_score)\n",
    "        times.append(end_time-start_time)\n",
    "        print('Test score = {}\\nTrain score = {}\\nTime = {}s\\n'.format(test_score, train_score, total_time))\n",
    "    print('Average test score: {}\\nAverage train score: {}\\nTotal time: {}s'.format(np.mean(test_scores), np.mean(train_scores), np.sum(times)))\n",
    "    return test_scores, train_scores, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_train_raw.values\n",
    "y_data = y_train_raw.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running split 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elrich/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score = 0.5334557640674337\n",
      "Train score = 0.9981441385709867\n",
      "Time = 26.0s\n",
      "\n",
      "Running split 2/10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_features=round(len(x_sm[0])/3))\n",
    "test_scores, train_scores, times = cross_validate(x_data, y_data, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running split 1/10\n",
      "Test score = 0.6736747634132997\n",
      "Train score = 0.924994827229464\n",
      "Time = 176.0s\n",
      "\n",
      "Running split 2/10\n",
      "Test score = 0.6112909921129099\n",
      "Train score = 0.9256978653530378\n",
      "Time = 181.0s\n",
      "\n",
      "Running split 3/10\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 3)\n",
    "test_scores, train_scores, times = cross_validate(x_data, y_data, xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_raw = pd.read_csv('../data/X_test.csv').drop('id', axis=1)\n",
    "# def output_pred(model, name):\n",
    "#     y_test_pred = rf.predict(x_test_raw)\n",
    "#     output = pd.DataFrame({'id':[float(i) for i in range(0, len(x_test_raw))], 'y': y_test_pred})\n",
    "#     output.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_pred(rf, 'rf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
