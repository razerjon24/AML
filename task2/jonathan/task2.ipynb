{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/X_train.csv\").drop('id', axis=1)\n",
    "test = pd.read_csv(\"../data/X_test.csv\").drop('id', axis=1)\n",
    "y = pd.read_csv(\"../data/y_train.csv\").y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x990</th>\n",
       "      <th>x991</th>\n",
       "      <th>x992</th>\n",
       "      <th>x993</th>\n",
       "      <th>x994</th>\n",
       "      <th>x995</th>\n",
       "      <th>x996</th>\n",
       "      <th>x997</th>\n",
       "      <th>x998</th>\n",
       "      <th>x999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.813592</td>\n",
       "      <td>1.596333</td>\n",
       "      <td>-1.577493</td>\n",
       "      <td>1.316790</td>\n",
       "      <td>1.224979</td>\n",
       "      <td>0.481390</td>\n",
       "      <td>-0.260872</td>\n",
       "      <td>1.040312</td>\n",
       "      <td>1.630821</td>\n",
       "      <td>4.411101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417060</td>\n",
       "      <td>1.870623</td>\n",
       "      <td>-1.150704</td>\n",
       "      <td>-0.370867</td>\n",
       "      <td>3.883882</td>\n",
       "      <td>-2.434579</td>\n",
       "      <td>-3.003603</td>\n",
       "      <td>2.826932</td>\n",
       "      <td>-2.295371</td>\n",
       "      <td>2.503751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.621952</td>\n",
       "      <td>1.622341</td>\n",
       "      <td>0.276690</td>\n",
       "      <td>0.507426</td>\n",
       "      <td>0.946101</td>\n",
       "      <td>0.113776</td>\n",
       "      <td>0.648369</td>\n",
       "      <td>0.924533</td>\n",
       "      <td>-0.439037</td>\n",
       "      <td>-0.073765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311276</td>\n",
       "      <td>-0.489654</td>\n",
       "      <td>0.176729</td>\n",
       "      <td>1.160717</td>\n",
       "      <td>-2.445714</td>\n",
       "      <td>0.433385</td>\n",
       "      <td>0.124162</td>\n",
       "      <td>-1.343699</td>\n",
       "      <td>0.363684</td>\n",
       "      <td>0.397675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.694772</td>\n",
       "      <td>-1.264971</td>\n",
       "      <td>0.192493</td>\n",
       "      <td>1.198083</td>\n",
       "      <td>1.785248</td>\n",
       "      <td>-0.303032</td>\n",
       "      <td>1.396465</td>\n",
       "      <td>0.768764</td>\n",
       "      <td>0.407531</td>\n",
       "      <td>0.290961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284238</td>\n",
       "      <td>-0.612937</td>\n",
       "      <td>0.106790</td>\n",
       "      <td>0.082038</td>\n",
       "      <td>-1.647803</td>\n",
       "      <td>1.015443</td>\n",
       "      <td>1.116481</td>\n",
       "      <td>-0.295231</td>\n",
       "      <td>0.702944</td>\n",
       "      <td>-0.530188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.380466</td>\n",
       "      <td>-1.332979</td>\n",
       "      <td>-0.868456</td>\n",
       "      <td>-0.254339</td>\n",
       "      <td>-0.704426</td>\n",
       "      <td>-1.653814</td>\n",
       "      <td>0.648190</td>\n",
       "      <td>-0.436893</td>\n",
       "      <td>0.924440</td>\n",
       "      <td>1.398371</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229356</td>\n",
       "      <td>1.427286</td>\n",
       "      <td>-0.992263</td>\n",
       "      <td>-0.233272</td>\n",
       "      <td>-1.001601</td>\n",
       "      <td>-1.132879</td>\n",
       "      <td>-0.929947</td>\n",
       "      <td>0.450716</td>\n",
       "      <td>-0.301820</td>\n",
       "      <td>1.326290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.461229</td>\n",
       "      <td>-0.997129</td>\n",
       "      <td>0.816687</td>\n",
       "      <td>-1.349971</td>\n",
       "      <td>-0.346954</td>\n",
       "      <td>-0.716830</td>\n",
       "      <td>0.950842</td>\n",
       "      <td>-0.604793</td>\n",
       "      <td>-0.866130</td>\n",
       "      <td>-0.634463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228485</td>\n",
       "      <td>-2.000328</td>\n",
       "      <td>0.282050</td>\n",
       "      <td>0.640746</td>\n",
       "      <td>-0.822140</td>\n",
       "      <td>0.161272</td>\n",
       "      <td>0.673704</td>\n",
       "      <td>-0.630556</td>\n",
       "      <td>-0.012413</td>\n",
       "      <td>0.127628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0 -1.813592  1.596333 -1.577493  1.316790  1.224979  0.481390 -0.260872   \n",
       "1  0.621952  1.622341  0.276690  0.507426  0.946101  0.113776  0.648369   \n",
       "2 -0.694772 -1.264971  0.192493  1.198083  1.785248 -0.303032  1.396465   \n",
       "3  1.380466 -1.332979 -0.868456 -0.254339 -0.704426 -1.653814  0.648190   \n",
       "4 -0.461229 -0.997129  0.816687 -1.349971 -0.346954 -0.716830  0.950842   \n",
       "\n",
       "         x7        x8        x9  ...      x990      x991      x992      x993  \\\n",
       "0  1.040312  1.630821  4.411101  ... -0.417060  1.870623 -1.150704 -0.370867   \n",
       "1  0.924533 -0.439037 -0.073765  ...  0.311276 -0.489654  0.176729  1.160717   \n",
       "2  0.768764  0.407531  0.290961  ... -0.284238 -0.612937  0.106790  0.082038   \n",
       "3 -0.436893  0.924440  1.398371  ...  1.229356  1.427286 -0.992263 -0.233272   \n",
       "4 -0.604793 -0.866130 -0.634463  ... -0.228485 -2.000328  0.282050  0.640746   \n",
       "\n",
       "       x994      x995      x996      x997      x998      x999  \n",
       "0  3.883882 -2.434579 -3.003603  2.826932 -2.295371  2.503751  \n",
       "1 -2.445714  0.433385  0.124162 -1.343699  0.363684  0.397675  \n",
       "2 -1.647803  1.015443  1.116481 -0.295231  0.702944 -0.530188  \n",
       "3 -1.001601 -1.132879 -0.929947  0.450716 -0.301820  1.326290  \n",
       "4 -0.822140  0.161272  0.673704 -0.630556 -0.012413  0.127628  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(pd.concat([train,test]))\n",
    "train_ = scaler.transform(train)\n",
    "train_ = pd.DataFrame(train_, columns=train.columns)\n",
    "test_ = scaler.transform(test)\n",
    "test_ = pd.DataFrame(test_, columns=train.columns)\n",
    "train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get balanced accuracy score\n",
    "def score(true, pred):\n",
    "    return balanced_accuracy_score(true, pred)\n",
    "\n",
    "# Oversample using SMOTE\n",
    "def oversample(x_data, y_data):\n",
    "    smote = SMOTE(ratio='not majority', random_state=42)\n",
    "    return smote.fit_sample(x_data, y_data)\n",
    "\n",
    "# Oversample and fit model for a CV split\n",
    "def run_fold(x_train, y_train, x_test, y_test, model):\n",
    "    # Oversample data\n",
    "    #x_train_sm, y_train_sm = oversample(x_train, y_train)\n",
    "    x_train_sm, y_train_sm = x_train, y_train\n",
    "    # Fit model\n",
    "    model.fit(x_train_sm, y_train_sm)\n",
    "    y_train_pred = model.predict(x_train_sm)\n",
    "    train_score = score(y_train_sm, y_train_pred)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    test_score = score(y_test, y_test_pred)\n",
    "    return test_score, train_score\n",
    "\n",
    "def cross_validate(x_data, y_data, model, variable):\n",
    "    # Split data into folds\n",
    "    n_splits = 10\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    folds = kf.split(x_data)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    times = []\n",
    "    split = 0\n",
    "    for train_index, test_index in folds:\n",
    "        split += 1\n",
    "        #print('Running split {}/{}'.format(split, n_splits))\n",
    "        x_train = x_data[train_index]\n",
    "        y_train = y_data[train_index]\n",
    "        x_test = x_data[test_index]\n",
    "        y_test = y_data[test_index]\n",
    "        start_time = time.time()\n",
    "        test_score, train_score = run_fold(x_train, y_train, x_test, y_test, model)\n",
    "        end_time = time.time()\n",
    "        total_time = round(end_time-start_time, ndigits=0)\n",
    "        test_scores.append(test_score)\n",
    "        train_scores.append(train_score)\n",
    "        times.append(end_time-start_time)\n",
    "        #print('Test score = {}\\nTrain score = {}\\nTime = {}s\\n'.format(test_score, train_score, total_time))\n",
    "    print('Average test score: {}\\nAverage train score: {}\\nTotal time: {}s'.format(np.mean(test_scores), np.mean(train_scores), np.sum(times)))\n",
    "    return test_scores, train_scores, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_pca(x_data, y_data, model, i):\n",
    "    # Split data into folds\n",
    "    n_splits = 10\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    folds = kf.split(x_data)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    times = []\n",
    "    split = 0\n",
    "    for train_index, test_index in folds:\n",
    "        split += 1\n",
    "        #print('Running split {}/{}'.format(split, n_splits))\n",
    "        x_train = x_data[train_index]\n",
    "        y_train = y_data[train_index]\n",
    "        x_test = x_data[test_index]\n",
    "        y_test = y_data[test_index]\n",
    "        pca = PCA(n_components = np.round(i,2))\n",
    "        pca.fit(pd.concat([pd.DataFrame(x_train),pd.DataFrame(x_test)]).values) \n",
    "        x_train_ = pd.DataFrame(pca.transform(x_train))\n",
    "        x_test_ = pd.DataFrame(pca.transform(x_test))\n",
    "        start_time = time.time()\n",
    "        test_score, train_score = run_fold(x_train_, y_train, x_test_, y_test, model)\n",
    "        end_time = time.time()\n",
    "        total_time = round(end_time-start_time, ndigits=0)\n",
    "        test_scores.append(test_score)\n",
    "        train_scores.append(train_score)\n",
    "        times.append(end_time-start_time)\n",
    "        #print('Test score = {}\\nTrain score = {}\\nTime = {}s\\n'.format(test_score, train_score, total_time))\n",
    "    print('Average test score: {}\\nAverage train score: {}\\nTotal time: {}s'.format(np.mean(test_scores), np.mean(train_scores), np.sum(times)))\n",
    "    return test_scores, train_scores, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "test_scores, train_scores, times = cross_validate(train_.values, y.ravel(), rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2,interaction_only = True)\n",
    "poly = poly.fit(pd.concat([train_,test_]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_tr = pd.DataFrame(poly.transform(train_))\n",
    "poly_ts = pd.DataFrame(poly.transform(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 0.74)\n",
    "pca.fit(pd.concat([train_,test_]).values)  \n",
    "len(pca.explained_variance_ratio_)\n",
    "# pca = PCA(n_components = 0.8)\n",
    "# pca.fit(pd.concat([poly_tr,poly_ts]).values)  \n",
    "# len(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.transform(train_)\n",
    "components_df = pd.DataFrame(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df.iloc[:,0:2].plot.scatter(x=0,y=1,c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_pca(tr,ts,y,clf):\n",
    "    test_scores = list()\n",
    "    train_scores = list()\n",
    "    times_iters = list()\n",
    "    for i in np.arange(0.7,0.9,0.01,dtype=float):\n",
    "        print('Start of {}'.format(np.round(i,2)))\n",
    "        test_scores, train_scores, times = cross_validate_pca(tr.values, y.ravel(), clf, i)\n",
    "        test_scores.append(np.mean(test_scores))\n",
    "        train_scores.append(np.mean(train_scores))\n",
    "        times_iters.append(np.sum(times))\n",
    "        print('End of {}, time: {}s'.format(np.round(i,2),np.sum(times)))\n",
    "    return test_scores, train_scores, times_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma = 'scale' ,kernel = 'rbf', decision_function_shape='ovo', cache_size=3000, random_state = 42, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of 0.7\n",
      "Average test score: 0.6956737045285502\n",
      "Average train score: 0.808815296826331\n",
      "Total time: 67.50490593910217s\n",
      "End of 0.7, time: 67.50490593910217s\n",
      "Start of 0.71\n",
      "Average test score: 0.6900015698639371\n",
      "Average train score: 0.8116032885591732\n",
      "Total time: 72.07505416870117s\n",
      "End of 0.71, time: 72.07505416870117s\n",
      "Start of 0.72\n",
      "Average test score: 0.6912694428369373\n",
      "Average train score: 0.8158177683694114\n",
      "Total time: 78.88805198669434s\n",
      "End of 0.72, time: 78.88805198669434s\n",
      "Start of 0.73\n",
      "Average test score: 0.6904153009117893\n",
      "Average train score: 0.8193354633369117\n",
      "Total time: 85.02613401412964s\n",
      "End of 0.73, time: 85.02613401412964s\n",
      "Start of 0.74\n",
      "Average test score: 0.6948273467943548\n",
      "Average train score: 0.8232173592620053\n",
      "Total time: 93.89329981803894s\n",
      "End of 0.74, time: 93.89329981803894s\n",
      "Start of 0.75\n",
      "Average test score: 0.6961116081260433\n",
      "Average train score: 0.8280202202017992\n",
      "Total time: 101.05408191680908s\n",
      "End of 0.75, time: 101.05408191680908s\n",
      "Start of 0.76\n",
      "Average test score: 0.6940649569210753\n",
      "Average train score: 0.8326151038366447\n",
      "Total time: 107.5488121509552s\n",
      "End of 0.76, time: 107.5488121509552s\n",
      "Start of 0.77\n",
      "Average test score: 0.6953589493982967\n",
      "Average train score: 0.8369453241702413\n",
      "Total time: 135.65680742263794s\n",
      "End of 0.77, time: 135.65680742263794s\n",
      "Start of 0.78\n",
      "Average test score: 0.6978989486145986\n",
      "Average train score: 0.8402353263587781\n",
      "Total time: 137.58396339416504s\n",
      "End of 0.78, time: 137.58396339416504s\n",
      "Start of 0.79\n",
      "Average test score: 0.7058763831465686\n",
      "Average train score: 0.8430579667389339\n",
      "Total time: 139.4414963722229s\n",
      "End of 0.79, time: 139.4414963722229s\n",
      "Start of 0.8\n",
      "Average test score: 0.7019395460105685\n",
      "Average train score: 0.8451553298670944\n",
      "Total time: 154.8937051296234s\n",
      "End of 0.8, time: 154.8937051296234s\n",
      "Start of 0.81\n",
      "Average test score: 0.703800398058923\n",
      "Average train score: 0.8468914385136243\n",
      "Total time: 163.80720806121826s\n",
      "End of 0.81, time: 163.80720806121826s\n",
      "Start of 0.82\n",
      "Average test score: 0.6977521148369628\n",
      "Average train score: 0.8511710946485505\n",
      "Total time: 177.71260809898376s\n",
      "End of 0.82, time: 177.71260809898376s\n",
      "Start of 0.83\n",
      "Average test score: 0.6970414693945057\n",
      "Average train score: 0.8573833985066187\n",
      "Total time: 183.12957668304443s\n",
      "End of 0.83, time: 183.12957668304443s\n",
      "Start of 0.84\n",
      "Average test score: 0.6933326549766665\n",
      "Average train score: 0.8611805182495692\n",
      "Total time: 200.87697339057922s\n",
      "End of 0.84, time: 200.87697339057922s\n",
      "Start of 0.85\n",
      "Average test score: 0.6931890449413921\n",
      "Average train score: 0.8640516622584837\n",
      "Total time: 205.48934960365295s\n",
      "End of 0.85, time: 205.48934960365295s\n",
      "Start of 0.86\n",
      "Average test score: 0.692320091010085\n",
      "Average train score: 0.8673640008799447\n",
      "Total time: 222.0402340888977s\n",
      "End of 0.86, time: 222.0402340888977s\n",
      "Start of 0.87\n",
      "Average test score: 0.6924170014876952\n",
      "Average train score: 0.8701820438333808\n",
      "Total time: 236.95121955871582s\n",
      "End of 0.87, time: 236.95121955871582s\n",
      "Start of 0.88\n",
      "Average test score: 0.6951638584714696\n",
      "Average train score: 0.8727824247596491\n",
      "Total time: 257.9374237060547s\n",
      "End of 0.88, time: 257.9374237060547s\n",
      "Start of 0.89\n",
      "Average test score: 0.6912321029288372\n",
      "Average train score: 0.8778325001248157\n",
      "Total time: 279.7521572113037s\n",
      "End of 0.89, time: 279.7521572113037s\n",
      "Start of 0.9\n",
      "Average test score: 0.6931111705296519\n",
      "Average train score: 0.8800842772775784\n",
      "Total time: 289.85552310943604s\n",
      "End of 0.9, time: 289.85552310943604s\n"
     ]
    }
   ],
   "source": [
    "test_scores, train_scores, times_iters = scores_pca(train_,test_,y,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_steps = [('scaler', StandardScaler()), ('pca',PCA(n_components=0.79)), ('SVM', svm.SVC(kernel = 'rbf', \n",
    "                                                                decision_function_shape='ovo', \n",
    "                                                                cache_size=3000, random_state = 42,\n",
    "                                                                class_weight = 'balanced'))]\n",
    "pipeline = Pipeline(pipe_steps)\n",
    "\n",
    "check_params = {\n",
    "    'SVM__C':[0.1,0.5,1,10,30,50],\n",
    "    'SVM__gamma':[0.001,0.005,0.01,0.05,0.07,0.1,0.5,1,5,10,'scale']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_grid = GridSearchCV(pipeline, param_grid=check_params, cv=10, scoring='balanced_accuracy')\n",
    "create_grid.fit(train,y)\n",
    "print(\"Best fit\")\n",
    "print(create_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma = 'scale' ,kernel = 'rbf', decision_function_shape='ovo', cache_size=3000, random_state = 42, class_weight = 'balanced')\n",
    "test_scores, train_scores, times = cross_validate(components_df.values, y.ravel(), clf)\n",
    "\n",
    "#WITH OVERSAMPLING\n",
    "# SVM 240 PCs (80.x%)\n",
    "# Average test score: 0.6624038730845622\n",
    "# Average train score: 0.9343450326600132\n",
    "# Total time: 493.02259135246277s\n",
    "# SVM PCs (90%)\n",
    "# Average test score: 0.649990375723468\n",
    "# Average train score: 0.9632699801869032\n",
    "# Total time: 975.6408638954163s\n",
    "# SVM 200 PCs (<80%)\n",
    "# Average test score: 0.6607910083259538\n",
    "# Average train score: 0.9231407317122418\n",
    "# Total time: 410.38625621795654s\n",
    "# SVM 238 PCs (80%)\n",
    "# Average test score: 0.6625778192190811\n",
    "# Average train score: 0.9326657068920167\n",
    "# Total time: 489.1878070831299s\n",
    "\n",
    "#WITH CLASS WEIGHTS\n",
    "#80%\n",
    "# Average test score: 0.6980772066781805\n",
    "# Average train score: 0.8506625620915867\n",
    "# Total time: 172.54561042785645s\n",
    "#70%\n",
    "# Average test score: 0.6946741811444423\n",
    "# Average train score: 0.8101701484126517\n",
    "# Total time: 80.19191813468933s\n",
    "#75%\n",
    "# Average test score: 0.6987988339325073\n",
    "# Average train score: 0.8314035482105762\n",
    "# Total time: 115.05265045166016s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ov, y_ov = oversample(components_df, y)\n",
    "# clf.fit(x_ov, y_ov)\n",
    "clf.fit(components_df.values, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(ax, clf_, xx, yy, **params):\n",
    "    Z = np.array([xx.ravel(), yy.ravel()] + [np.repeat(0, xx.ravel().size) for _ in range(236)]).T\n",
    "    Z = clf_.predict(Z).reshape(xx.shape) \n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "def make_meshgrid(x, y, h=.1):\n",
    "    x_min, x_max = x.min() - 1 , x.max() + 1\n",
    "    y_min, y_max = y.min() - 1 , y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.array(components_df.iloc[:,0])\n",
    "X1 = np.array(components_df.iloc[:,1])\n",
    "xx, yy = make_meshgrid(X0,X1)\n",
    "len(xx.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.array(components_df.iloc[:,0])\n",
    "X1 = np.array(components_df.iloc[:,1])\n",
    "xx, yy = make_meshgrid(X0,X1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.patch.set_facecolor('white')\n",
    "cdict1={0:'lime',1:'deeppink', 2:'purple'}\n",
    "\n",
    "Y_tar_list = y.tolist()\n",
    "labels1 = Y_tar_list\n",
    "\n",
    "labl1 = {0:'0', 1:'1', 2:'2'}\n",
    "marker1= {0:'*',1:'d',2:'h'}\n",
    "alpha1={0:.6, 1:0.3, 2:0.6}\n",
    "\n",
    "for l1 in np.unique(labels1):\n",
    "    ix1 = np.where(labels1==l1)\n",
    "    ax.scatter(X0[ix1],X1[ix1], c=cdict1[l1], label=labl1[l1],s=70, \n",
    "               marker=marker1[l1], alpha=alpha1[l1])\n",
    "\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=40,\n",
    "          facecolors='none', edgecolors='navy', label='Support Vectors', alpha=0.5)\n",
    "\n",
    "plot_contours(ax, classify, xx, yy, cmap='seismic', alpha=0.4)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.xlabel(\"1st Principal Component\", fontsize=14)\n",
    "plt.ylabel(\"2nd Principal Component\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_test = pca.transform(test_)\n",
    "components_test_df = pd.DataFrame(components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = clf.predict(components_test_df)\n",
    "file_test = \"svm_pca_cw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id':[float(i) for i in range(0,len(test_y))],'y':test_y})\n",
    "output.to_csv(\"{}.csv\".format(file_test),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
